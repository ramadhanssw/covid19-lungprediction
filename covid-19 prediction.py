# -*- coding: utf-8 -*-
"""Group 6_AU Winter Program Final Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wvOJrcEJ6DTHubDDQj2Wv1qucve2DjGH

# Preprocess
"""

# running on Google Colab
from google.colab import drive
drive.mount('/gdrive')

# Commented out IPython magic to ensure Python compatibility.
# make sure you add shortcut of this FP Folder on your Google Drive
# your current working dir
# %pwd

# Commented out IPython magic to ensure Python compatibility.
# change current working dir
# %cd /gdrive/MyDrive/Covid\ Lung\ Xray\ detection

# Commented out IPython magic to ensure Python compatibility.
# check list of working dir
# %ls

import pandas as pd
import os
import numpy as np
import cv2

data_path = 'dataset'
categories = os.listdir(data_path)
labels = [i for i in range(len(categories))]

label_dict = dict(zip(categories,labels))

print(label_dict)
print(categories)
print(labels)

# Commented out IPython magic to ensure Python compatibility.
from matplotlib import pyplot as plt
# %matplotlib inline

cov_pos = 0
cov_neg = 0
for category in categories:
    folder_path = os.path.join(data_path,category)
    totalFiles = 0
    for base, _, files in os.walk(folder_path):
        print('Counting files in : ',base)
        for f in files:
            totalFiles += 1
        if category == "Covid Positive":
            cov_pos = totalFiles
        else:
            cov_neg = totalFiles

plt.figure(figsize=(10,10))
plt.bar(categories, [cov_pos, cov_neg])
plt.title("Class Distribution of dataset")
plt.show()

"""we are dealing with imbalance dataset and our interest is on positive class

therefore, we are going use Recall for evaluation metrics
"""

img_size = 128 #resizing images
data = []
target = []

for category in categories:
    folder_path = os.path.join(data_path,category)
    img_names = os.listdir(folder_path)
        
    for img_name in img_names:
        img_path = os.path.join(folder_path,img_name)
        img = cv2.imread(img_path)

        try:
            gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)           
            #Coverting the image into gray scale
            resized = cv2.resize(gray,(img_size,img_size))
            #resizing the gray scale into 100x100, since we need a fixed 
            #common size for all the images in the dataset
            data.append(resized)
            target.append(label_dict[category])
            #appending the image and the label(categorized) into the list 
            #(dataset)

        except Exception as e:
            print('Exception:',e)
            #if any exception rasied, the exception will be printed here.
            #And pass to the next image

import numpy as np
from keras.utils import np_utils

data = np.array(data)/255.0
data = np.reshape(data,(data.shape[0],img_size,img_size,1))
target = np.array(target)

new_target = np_utils.to_categorical(target)

new_target

data_filepath = os.path.join(data_path,'data')
target_filepath = os.path.join(data_path,'target')
np.save(data_filepath, data)
np.save(target_filepath, new_target)

"""# Training"""

data = np.load('dataset/data.npy')
target = np.load('dataset/target.npy')

from keras.models import Sequential,Model
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, Activation, MaxPooling2D
from keras.utils import normalize
from keras.layers import Concatenate
from keras import Input
from keras.callbacks import ModelCheckpoint
from keras.metrics import Recall

input_shape = data.shape[1:] #50,50,1
inp = Input(shape=input_shape)
convs = []

parrallel_kernels = [3,5,7]

for k in range(len(parrallel_kernels)):
    conv = Conv2D(128, parrallel_kernels[k],padding='same',activation='relu',\
                  input_shape=input_shape,strides=1)(inp)
    convs.append(conv)

out = Concatenate()(convs)
conv_model = Model(inp, out)

model = Sequential()
model.add(conv_model)

model.add(Conv2D(64,(3,3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(32,(3,3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Flatten())
model.add(Dropout(0.5))
model.add(Dense(128,activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(64,activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(2,input_dim=128, activation='sigmoid'))
model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=Recall())

model.summary()

input_shape

from sklearn.model_selection import train_test_split

train_data,test_data,train_target,test_target = train_test_split(data,target,test_size=0.2)

train_target.shape

checkpoint = ModelCheckpoint('model-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')
history = model.fit(train_data,train_target,epochs=5,callbacks=[checkpoint],validation_split=0.2)

"""# Testing"""

print(model.evaluate(test_data,test_target))

plt.plot(history.history['loss'],'r',label='training loss')
plt.plot(history.history['val_loss'],label='validation loss')
plt.xlabel('# epochs')
plt.ylabel('loss')
plt.legend()
plt.show()

plt.plot(history.history['recall'],'r',label='training recall')
plt.plot(history.history['val_recall'],label='validation recall')
plt.xlabel('# epochs')
plt.ylabel('loss')
plt.legend()
plt.show()